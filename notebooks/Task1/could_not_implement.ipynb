{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AIxSuture TimeSformer Model - OSS Challenge 2025\n",
        "## Task 1: Global Rating Score (GRS) Classification\n",
        "\n",
        "**Model Architecture:** TimeSformer for video understanding\n",
        "**Dataset:** AIxSuture (314 videos, 157 students, 3 raters)\n",
        "**Task:** 4-class GRS classification (Novice, Intermediate, Proficient, Expert)\n",
        "\n",
        "**Training Strategy:**\n",
        "- Load preprocessed AIxSuture data\n",
        "- TimeSformer with divided space-time attention\n",
        "- Multi-rater aggregated ground truth\n",
        "- Session-aware evaluation (PRE vs POST)\n",
        "- Macro-F1 and Expected Cost metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "import json\n",
        "from collections import Counter, defaultdict\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')\n",
        "\n",
        "torch.manual_seed(2025)\n",
        "np.random.seed(2025)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(2025)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Preprocessed AIxSuture Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset Loaded:\n",
            "  Total videos: 290\n",
            "  Students: 157\n",
            "  Sessions: ['POST', 'PRE']\n",
            "  Investigators: ['A', 'B', 'C']\n",
            "  Train sequences: 4078\n",
            "  Val sequences: 2291\n",
            "  Train students: 18\n",
            "  Val students: 10\n",
            "\n",
            "Class distribution:\n",
            "  Novice: Train=2715, Val=0\n",
            "  Intermediate: Train=909, Val=239\n",
            "  Proficient: Train=227, Val=1599\n",
            "  Expert: Train=227, Val=453\n",
            "\n",
            "Preprocessing config:\n",
            "  Sequence length: 16\n",
            "  Frame size: (224, 224)\n",
            "  FPS: 5\n",
            "  Aggregation: average\n"
          ]
        }
      ],
      "source": [
        "def load_aixsuture_data():\n",
        "    data_path = '../processed_data/aixsuture_processed_data.pkl'\n",
        "    metadata_path = '../processed_data/aixsuture_metadata.json'\n",
        "    \n",
        "    if not os.path.exists(data_path):\n",
        "        raise FileNotFoundError(f\"Preprocessed data not found at {data_path}. Please run preprocessing first.\")\n",
        "    \n",
        "    with open(data_path, 'rb') as f:\n",
        "        data = pickle.load(f)\n",
        "    \n",
        "    with open(metadata_path, 'r') as f:\n",
        "        metadata = json.load(f)\n",
        "    \n",
        "    return data, metadata\n",
        "\n",
        "data, metadata = load_aixsuture_data()\n",
        "\n",
        "CONFIG = data['config']\n",
        "GRS_MAPPING = data['grs_mapping']\n",
        "train_data = data['train_data']\n",
        "val_data = data['val_data']\n",
        "train_students = data['train_students']\n",
        "val_students = data['val_students']\n",
        "\n",
        "print(f\"Dataset Loaded:\")\n",
        "print(f\"  Total videos: {metadata['dataset_info']['total_videos']}\")\n",
        "print(f\"  Students: {metadata['dataset_info']['total_students']}\")\n",
        "print(f\"  Sessions: {metadata['dataset_info']['sessions']}\")\n",
        "print(f\"  Investigators: {metadata['dataset_info']['investigators']}\")\n",
        "print(f\"  Train sequences: {len(train_data)}\")\n",
        "print(f\"  Val sequences: {len(val_data)}\")\n",
        "print(f\"  Train students: {len(train_students)}\")\n",
        "print(f\"  Val students: {len(val_students)}\")\n",
        "\n",
        "print(f\"\\nClass distribution:\")\n",
        "for class_id, label in enumerate(GRS_MAPPING['labels']):\n",
        "    train_count = metadata['class_distribution']['train'].get(str(class_id), 0)\n",
        "    val_count = metadata['class_distribution']['val'].get(str(class_id), 0)\n",
        "    print(f\"  {label}: Train={train_count}, Val={val_count}\")\n",
        "\n",
        "print(f\"\\nPreprocessing config:\")\n",
        "print(f\"  Sequence length: {CONFIG['sequence_length']}\")\n",
        "print(f\"  Frame size: {CONFIG['frame_size']}\")\n",
        "print(f\"  FPS: {CONFIG['fps']}\")\n",
        "print(f\"  Aggregation: {CONFIG['aggregation_strategy']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. TimeSformer Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "TimeSformer Model Created:\n",
            "  Total parameters: 114,180,100\n",
            "  Trainable parameters: 114,180,100\n",
            "  Model size: base\n",
            "  Input shape: (batch, 16, 3, 224, 224)\n",
            "  Output classes: 4\n"
          ]
        }
      ],
      "source": [
        "class PatchEmbed(nn.Module):\n",
        "    def __init__(self, img_size=224, patch_size=16, in_chans=3, embed_dim=768):\n",
        "        super().__init__()\n",
        "        self.img_size = img_size\n",
        "        self.patch_size = patch_size\n",
        "        self.num_patches = (img_size // patch_size) ** 2\n",
        "        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        B, T, C, H, W = x.shape\n",
        "        x = x.reshape(B * T, C, H, W)\n",
        "        x = self.proj(x)\n",
        "        x = x.flatten(2).transpose(1, 2)\n",
        "        x = x.reshape(B, T, self.num_patches, -1)\n",
        "        return x\n",
        "\n",
        "class TimeSformerBlock(nn.Module):\n",
        "    def __init__(self, dim, num_heads, mlp_ratio=4.0, dropout=0.1, attention_type='divided_space_time'):\n",
        "        super().__init__()\n",
        "        self.attention_type = attention_type\n",
        "        self.norm1 = nn.LayerNorm(dim)\n",
        "        self.norm2 = nn.LayerNorm(dim)\n",
        "        \n",
        "        if attention_type == 'divided_space_time':\n",
        "            self.temporal_attn = nn.MultiheadAttention(dim, num_heads, dropout=dropout, batch_first=True)\n",
        "            self.spatial_attn = nn.MultiheadAttention(dim, num_heads, dropout=dropout, batch_first=True)\n",
        "            self.norm_temporal = nn.LayerNorm(dim)\n",
        "        else:\n",
        "            self.attn = nn.MultiheadAttention(dim, num_heads, dropout=dropout, batch_first=True)\n",
        "        \n",
        "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(dim, mlp_hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(mlp_hidden_dim, dim),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "    \n",
        "    def forward(self, x, cls_token):\n",
        "        B, T, N, D = x.shape\n",
        "        \n",
        "        if self.attention_type == 'divided_space_time':\n",
        "            cls_token = cls_token.unsqueeze(1).repeat(1, T, 1, 1)\n",
        "            x_with_cls = torch.cat([cls_token, x], dim=2)\n",
        "            \n",
        "            x_temporal = x_with_cls.permute(0, 2, 1, 3).reshape(B * (N + 1), T, D)\n",
        "            x_temporal_out, _ = self.temporal_attn(x_temporal, x_temporal, x_temporal)\n",
        "            x_temporal_out = x_temporal_out.reshape(B, N + 1, T, D).permute(0, 2, 1, 3)\n",
        "            \n",
        "            x_temporal_out = x_with_cls + x_temporal_out\n",
        "            x_temporal_out = self.norm_temporal(x_temporal_out)\n",
        "            \n",
        "            x_spatial = x_temporal_out.reshape(B * T, N + 1, D)\n",
        "            x_spatial_out, _ = self.spatial_attn(x_spatial, x_spatial, x_spatial)\n",
        "            x_spatial_out = x_spatial_out.reshape(B, T, N + 1, D)\n",
        "            \n",
        "            x_out = x_temporal_out + x_spatial_out\n",
        "            x_out = self.norm1(x_out)\n",
        "            \n",
        "            cls_token_out = x_out[:, :, 0, :].mean(dim=1)\n",
        "            x_out = x_out[:, :, 1:, :]\n",
        "        else:\n",
        "            print(\"x shape:\", x.shape)\n",
        "            print(\"cls_token shape before repeat:\", cls_token.shape)\n",
        "            print(\"cls_token shape after repeat:\", cls_token.unsqueeze(1).repeat(1, T, 1, 1).shape)\n",
        "            cls_token_expanded = cls_token.unsqueeze(1).unsqueeze(1).repeat(1, T, 1, 1)\n",
        "            x_with_cls = torch.cat([cls_token_expanded, x], dim=2)\n",
        "            x_flat = x_with_cls.reshape(B, T * (N + 1), D)\n",
        "            \n",
        "            x_attn, _ = self.attn(x_flat, x_flat, x_flat)\n",
        "            x_attn = x_flat + x_attn\n",
        "            x_attn = self.norm1(x_attn)\n",
        "            \n",
        "            cls_token_out = x_attn[:, 0, :]\n",
        "            x_out = x_attn[:, 1:, :].reshape(B, T, N, D)\n",
        "        \n",
        "        x_out_flat = x_out.reshape(B * T, N, D)\n",
        "        mlp_out = self.mlp(x_out_flat)\n",
        "        x_out = x_out_flat + mlp_out\n",
        "        x_out = self.norm2(x_out)\n",
        "        x_out = x_out.reshape(B, T, N, D)\n",
        "        \n",
        "        return x_out, cls_token_out\n",
        "\n",
        "class TimeSformer(nn.Module):\n",
        "    def __init__(self, img_size=224, patch_size=16, num_classes=4, num_frames=16,\n",
        "                 embed_dim=768, depth=12, num_heads=12, mlp_ratio=4.0, dropout=0.1,\n",
        "                 attention_type='divided_space_time'):\n",
        "        super().__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.num_frames = num_frames\n",
        "        self.embed_dim = embed_dim\n",
        "        \n",
        "        self.patch_embed = PatchEmbed(img_size, patch_size, 3, embed_dim)\n",
        "        num_patches = self.patch_embed.num_patches\n",
        "        \n",
        "        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
        "        self.pos_embed = nn.Parameter(torch.zeros(1, num_patches, embed_dim))\n",
        "        self.temporal_embed = nn.Parameter(torch.zeros(1, num_frames, embed_dim))\n",
        "        \n",
        "        self.blocks = nn.ModuleList([\n",
        "            TimeSformerBlock(embed_dim, num_heads, mlp_ratio, dropout, attention_type)\n",
        "            for _ in range(depth)\n",
        "        ])\n",
        "        \n",
        "        self.norm = nn.LayerNorm(embed_dim)\n",
        "        self.head = nn.Linear(embed_dim, num_classes)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self._init_weights()\n",
        "    \n",
        "    def _init_weights(self):\n",
        "        nn.init.trunc_normal_(self.pos_embed, std=0.02)\n",
        "        nn.init.trunc_normal_(self.temporal_embed, std=0.02)\n",
        "        nn.init.trunc_normal_(self.cls_token, std=0.02)\n",
        "        \n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.trunc_normal_(m.weight, std=0.02)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.LayerNorm):\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "                nn.init.constant_(m.weight, 1.0)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        B, T, C, H, W = x.shape\n",
        "        \n",
        "        x = self.patch_embed(x)\n",
        "        B, T, N, D = x.shape\n",
        "        \n",
        "        x = x + self.pos_embed.unsqueeze(1)\n",
        "        x = x + self.temporal_embed.unsqueeze(2)\n",
        "        \n",
        "        x = self.dropout(x)\n",
        "        \n",
        "        cls_token = self.cls_token.expand(B, -1, -1)\n",
        "        \n",
        "        for block in self.blocks:\n",
        "            x, cls_token = block(x, cls_token)\n",
        "        \n",
        "        cls_token = self.norm(cls_token)\n",
        "        logits = self.head(cls_token)\n",
        "        \n",
        "        return logits\n",
        "\n",
        "def create_timesformer_model(num_classes=4, num_frames=16, model_size='base'):\n",
        "    if model_size == 'small':\n",
        "        config = {\n",
        "            'embed_dim': 384,\n",
        "            'depth': 8,\n",
        "            'num_heads': 6,\n",
        "            'mlp_ratio': 4.0\n",
        "        }\n",
        "    elif model_size == 'base':\n",
        "        config = {\n",
        "            'embed_dim': 768,\n",
        "            'depth': 12,\n",
        "            'num_heads': 12,\n",
        "            'mlp_ratio': 4.0\n",
        "        }\n",
        "    else:\n",
        "        config = {\n",
        "            'embed_dim': 1024,\n",
        "            'depth': 16,\n",
        "            'num_heads': 16,\n",
        "            'mlp_ratio': 4.0\n",
        "        }\n",
        "    \n",
        "    model = TimeSformer(\n",
        "        img_size=224,\n",
        "        patch_size=16,\n",
        "        num_classes=num_classes,\n",
        "        num_frames=num_frames,\n",
        "        **config\n",
        "    )\n",
        "    \n",
        "    return model\n",
        "\n",
        "model = create_timesformer_model(\n",
        "    num_classes=len(GRS_MAPPING['classes']),\n",
        "    num_frames=CONFIG['sequence_length'],\n",
        "    model_size='base'\n",
        ").to(device)\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"\\nTimeSformer Model Created:\")\n",
        "print(f\"  Total parameters: {total_params:,}\")\n",
        "print(f\"  Trainable parameters: {trainable_params:,}\")\n",
        "print(f\"  Model size: base\")\n",
        "print(f\"  Input shape: (batch, {CONFIG['sequence_length']}, 3, 224, 224)\")\n",
        "print(f\"  Output classes: {len(GRS_MAPPING['classes'])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. AIxSuture Dataset Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Datasets created:\n",
            "  Train dataset: 4078 sequences\n",
            "  Val dataset: 2291 sequences\n",
            "\n",
            "Sample data:\n",
            "  Sequence shape: torch.Size([16, 3, 224, 224])\n",
            "  Label: 1 (Intermediate)\n",
            "  Student: BOG917\n",
            "  Session: PRE\n",
            "  GRS Total: 17.666666666666668\n"
          ]
        }
      ],
      "source": [
        "class AIxSutureDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, training_data, transform=None, mode='train', augment=False):\n",
        "        self.training_data = training_data\n",
        "        self.transform = transform\n",
        "        self.mode = mode\n",
        "        self.augment = augment\n",
        "        \n",
        "        if augment and mode == 'train':\n",
        "            self.spatial_transform = transforms.Compose([\n",
        "                transforms.RandomHorizontalFlip(p=0.5),\n",
        "                transforms.RandomRotation(degrees=5),\n",
        "                transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)\n",
        "            ])\n",
        "        else:\n",
        "            self.spatial_transform = None\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.training_data)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        item = self.training_data[idx]\n",
        "        \n",
        "        if item.get('sequence_type') == 'simulated':\n",
        "            sequence_tensor = torch.randn(\n",
        "                CONFIG['sequence_length'], 3,\n",
        "                CONFIG['frame_size'][0], CONFIG['frame_size'][1]\n",
        "            )\n",
        "        else:\n",
        "            frames = []\n",
        "            for frame_info in item['sequence_frames']:\n",
        "                if frame_info.get('simulated', False):\n",
        "                    frame_tensor = torch.randn(3, CONFIG['frame_size'][0], CONFIG['frame_size'][1])\n",
        "                else:\n",
        "                    try:\n",
        "                        import cv2\n",
        "                        frame = cv2.imread(frame_info['path'])\n",
        "                        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "                        frame = cv2.resize(frame, CONFIG['frame_size'])\n",
        "                        frame_tensor = torch.from_numpy(frame).float() / 255.0\n",
        "                        frame_tensor = frame_tensor.permute(2, 0, 1)\n",
        "                    except:\n",
        "                        frame_tensor = torch.randn(3, CONFIG['frame_size'][0], CONFIG['frame_size'][1])\n",
        "                \n",
        "                if self.spatial_transform is not None:\n",
        "                    frame_tensor = self.spatial_transform(frame_tensor)\n",
        "                \n",
        "                frames.append(frame_tensor)\n",
        "            \n",
        "            sequence_tensor = torch.stack(frames)\n",
        "        \n",
        "        if self.transform:\n",
        "            sequence_tensor = self.transform(sequence_tensor)\n",
        "        \n",
        "        label = torch.tensor(item['grs_class'], dtype=torch.long)\n",
        "        \n",
        "        return {\n",
        "            'sequence': sequence_tensor,\n",
        "            'label': label,\n",
        "            'video_name': item['video_name'],\n",
        "            'student_id': item['student_id'],\n",
        "            'session': item['session'],\n",
        "            'grs_total': item['grs_total'],\n",
        "            'sequence_idx': item['sequence_idx']\n",
        "        }\n",
        "\n",
        "def normalize_sequence(sequence):\n",
        "    mean = torch.tensor(CONFIG['imagenet_mean']).view(1, 3, 1, 1)\n",
        "    std = torch.tensor(CONFIG['imagenet_std']).view(1, 3, 1, 1)\n",
        "    return (sequence - mean) / std\n",
        "\n",
        "train_dataset = AIxSutureDataset(\n",
        "    train_data,\n",
        "    transform=normalize_sequence,\n",
        "    mode='train',\n",
        "    augment=True\n",
        ")\n",
        "\n",
        "val_dataset = AIxSutureDataset(\n",
        "    val_data,\n",
        "    transform=normalize_sequence,\n",
        "    mode='val',\n",
        "    augment=False\n",
        ")\n",
        "\n",
        "print(f\"\\nDatasets created:\")\n",
        "print(f\"  Train dataset: {len(train_dataset)} sequences\")\n",
        "print(f\"  Val dataset: {len(val_dataset)} sequences\")\n",
        "\n",
        "if len(train_dataset) > 0:\n",
        "    sample = train_dataset[0]\n",
        "    print(f\"\\nSample data:\")\n",
        "    print(f\"  Sequence shape: {sample['sequence'].shape}\")\n",
        "    print(f\"  Label: {sample['label']} ({GRS_MAPPING['labels'][sample['label']]})\")\n",
        "    print(f\"  Student: {sample['student_id']}\")\n",
        "    print(f\"  Session: {sample['session']}\")\n",
        "    print(f\"  GRS Total: {sample['grs_total']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Training Configuration and Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Class weights:\n",
            "  Novice: 0.376\n",
            "  Intermediate: 1.122\n",
            "  Proficient: 4.491\n",
            "  Expert: 4.491\n",
            "\n",
            "Data loaders created:\n",
            "  Train batches: 1019\n",
            "  Val batches: 573\n",
            "  Batch size: 4\n",
            "  Using weighted sampling: True\n"
          ]
        }
      ],
      "source": [
        "TRAINING_CONFIG = {\n",
        "    'batch_size': 4,\n",
        "    'num_epochs': 50,\n",
        "    'learning_rate': 1e-4,\n",
        "    'weight_decay': 1e-4,\n",
        "    'warmup_epochs': 5,\n",
        "    'patience': 10,\n",
        "    'use_class_weights': True,\n",
        "    'gradient_clip': 1.0,\n",
        "    'save_best_model': True\n",
        "}\n",
        "\n",
        "def compute_class_weights(train_labels):\n",
        "    unique_classes = np.unique(train_labels)\n",
        "    class_weights = compute_class_weight(\n",
        "        'balanced',\n",
        "        classes=unique_classes,\n",
        "        y=train_labels\n",
        "    )\n",
        "    return torch.FloatTensor(class_weights).to(device)\n",
        "\n",
        "train_labels = [item['grs_class'] for item in train_data]\n",
        "class_weights = compute_class_weights(train_labels) if TRAINING_CONFIG['use_class_weights'] else None\n",
        "\n",
        "if class_weights is not None:\n",
        "    print(f\"\\nClass weights:\")\n",
        "    for i, (label, weight) in enumerate(zip(GRS_MAPPING['labels'], class_weights)):\n",
        "        print(f\"  {label}: {weight:.3f}\")\n",
        "\n",
        "def create_weighted_sampler(dataset):\n",
        "    labels = [item['grs_class'] for item in dataset.training_data]\n",
        "    class_counts = Counter(labels)\n",
        "    \n",
        "    weights = []\n",
        "    for label in labels:\n",
        "        weights.append(1.0 / class_counts[label])\n",
        "    \n",
        "    return WeightedRandomSampler(weights, len(weights), replacement=True)\n",
        "\n",
        "train_sampler = create_weighted_sampler(train_dataset) if TRAINING_CONFIG['use_class_weights'] else None\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=TRAINING_CONFIG['batch_size'],\n",
        "    sampler=train_sampler,\n",
        "    shuffle=(train_sampler is None),\n",
        "    num_workers=2,\n",
        "    pin_memory=True,\n",
        "    drop_last=True\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=TRAINING_CONFIG['batch_size'],\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "print(f\"\\nData loaders created:\")\n",
        "print(f\"  Train batches: {len(train_loader)}\")\n",
        "print(f\"  Val batches: {len(val_loader)}\")\n",
        "print(f\"  Batch size: {TRAINING_CONFIG['batch_size']}\")\n",
        "print(f\"  Using weighted sampling: {train_sampler is not None}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Loss Function and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training setup:\n",
            "  Optimizer: AdamW\n",
            "  Learning rate: 0.0001\n",
            "  Weight decay: 0.0001\n",
            "  Loss function: Combined (CE + Expected Cost)\n",
            "  Scheduler: Cosine with warmup\n",
            "  Warmup steps: 5095\n",
            "  Total steps: 50950\n"
          ]
        }
      ],
      "source": [
        "def expected_cost_loss(predictions, targets, cost_matrix=None):\n",
        "    if cost_matrix is None:\n",
        "        num_classes = len(GRS_MAPPING['classes'])\n",
        "        cost_matrix = torch.zeros(num_classes, num_classes).to(device)\n",
        "        for i in range(num_classes):\n",
        "            for j in range(num_classes):\n",
        "                cost_matrix[i, j] = abs(i - j)\n",
        "    \n",
        "    probs = F.softmax(predictions, dim=1)\n",
        "    costs = torch.sum(probs * cost_matrix[targets], dim=1)\n",
        "    return costs.mean()\n",
        "\n",
        "class CombinedLoss(nn.Module):\n",
        "    def __init__(self, class_weights=None, alpha=0.7, beta=0.3):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.ce_loss = nn.CrossEntropyLoss(weight=class_weights)\n",
        "    \n",
        "    def forward(self, predictions, targets):\n",
        "        ce_loss = self.ce_loss(predictions, targets)\n",
        "        ec_loss = expected_cost_loss(predictions, targets)\n",
        "        return self.alpha * ce_loss + self.beta * ec_loss\n",
        "\n",
        "criterion = CombinedLoss(class_weights=class_weights)\n",
        "\n",
        "optimizer = optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=TRAINING_CONFIG['learning_rate'],\n",
        "    weight_decay=TRAINING_CONFIG['weight_decay']\n",
        ")\n",
        "\n",
        "def get_cosine_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps):\n",
        "    def lr_lambda(current_step):\n",
        "        if current_step < num_warmup_steps:\n",
        "            return float(current_step) / float(max(1, num_warmup_steps))\n",
        "        progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n",
        "        return max(0.0, 0.5 * (1.0 + np.cos(np.pi * progress)))\n",
        "    \n",
        "    return optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
        "\n",
        "num_training_steps = len(train_loader) * TRAINING_CONFIG['num_epochs']\n",
        "num_warmup_steps = len(train_loader) * TRAINING_CONFIG['warmup_epochs']\n",
        "\n",
        "scheduler = get_cosine_schedule_with_warmup(\n",
        "    optimizer, num_warmup_steps, num_training_steps\n",
        ")\n",
        "\n",
        "print(f\"\\nTraining setup:\")\n",
        "print(f\"  Optimizer: AdamW\")\n",
        "print(f\"  Learning rate: {TRAINING_CONFIG['learning_rate']}\")\n",
        "print(f\"  Weight decay: {TRAINING_CONFIG['weight_decay']}\")\n",
        "print(f\"  Loss function: Combined (CE + Expected Cost)\")\n",
        "print(f\"  Scheduler: Cosine with warmup\")\n",
        "print(f\"  Warmup steps: {num_warmup_steps}\")\n",
        "print(f\"  Total steps: {num_training_steps}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting training for 50 epochs...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1 [Train]:   0%|          | 0/1019 [00:01<?, ?it/s]\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Sizes of tensors must match except in dimension 2. Expected size 1 but got size 4 for tensor number 1 in the list.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[35], line 153\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    140\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_losses\u001b[39m\u001b[38;5;124m'\u001b[39m: train_losses,\n\u001b[1;32m    141\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_losses\u001b[39m\u001b[38;5;124m'\u001b[39m: val_losses,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal_sessions\u001b[39m\u001b[38;5;124m'\u001b[39m: val_sessions\n\u001b[1;32m    151\u001b[0m     }\n\u001b[0;32m--> 153\u001b[0m training_history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[35], line 99\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mStarting training for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTRAINING_CONFIG[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_epochs\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m epochs...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(TRAINING_CONFIG[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_epochs\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[0;32m---> 99\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m     val_loss, val_acc, macro_f1, val_preds, val_labels, val_videos, val_students, val_sessions \u001b[38;5;241m=\u001b[39m validate_epoch(\n\u001b[1;32m    101\u001b[0m         model, val_loader, criterion, epoch\n\u001b[1;32m    102\u001b[0m     )\n\u001b[1;32m    104\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
            "Cell \u001b[0;32mIn[35], line 15\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, train_loader, criterion, optimizer, scheduler, epoch)\u001b[0m\n\u001b[1;32m     11\u001b[0m labels \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     13\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 15\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequences\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     18\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
            "File \u001b[0;32m~/miniconda3/envs/SI/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/SI/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "Cell \u001b[0;32mIn[31], line 142\u001b[0m, in \u001b[0;36mTimeSformer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    139\u001b[0m cls_token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcls_token\u001b[38;5;241m.\u001b[39mexpand(B, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[0;32m--> 142\u001b[0m     x, cls_token \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcls_token\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m cls_token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(cls_token)\n\u001b[1;32m    145\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead(cls_token)\n",
            "File \u001b[0;32m~/miniconda3/envs/SI/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/SI/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "Cell \u001b[0;32mIn[31], line 45\u001b[0m, in \u001b[0;36mTimeSformerBlock.forward\u001b[0;34m(self, x, cls_token)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdivided_space_time\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     44\u001b[0m     cls_token \u001b[38;5;241m=\u001b[39m cls_token\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;241m1\u001b[39m, T, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 45\u001b[0m     x_with_cls \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcls_token\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m     x_temporal \u001b[38;5;241m=\u001b[39m x_with_cls\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(B \u001b[38;5;241m*\u001b[39m (N \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), T, D)\n\u001b[1;32m     48\u001b[0m     x_temporal_out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemporal_attn(x_temporal, x_temporal, x_temporal)\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 2. Expected size 1 but got size 4 for tensor number 1 in the list."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "def train_epoch(model, train_loader, criterion, optimizer, scheduler, epoch):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    pbar = tqdm(train_loader, desc=f'Epoch {epoch+1} [Train]')\n",
        "    \n",
        "    for batch_idx, batch in enumerate(pbar):\n",
        "        sequences = batch['sequence'].to(device)\n",
        "        labels = batch['label'].to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        outputs = model(sequences)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        if TRAINING_CONFIG['gradient_clip'] > 0:\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), TRAINING_CONFIG['gradient_clip'])\n",
        "        \n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        \n",
        "        total_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "        \n",
        "        current_lr = scheduler.get_last_lr()[0]\n",
        "        pbar.set_postfix({\n",
        "            'Loss': f'{loss.item():.4f}',\n",
        "            'Acc': f'{100.*correct/total:.2f}%',\n",
        "            'LR': f'{current_lr:.2e}'\n",
        "        })\n",
        "    \n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    accuracy = 100. * correct / total\n",
        "    \n",
        "    return avg_loss, accuracy\n",
        "\n",
        "def validate_epoch(model, val_loader, criterion, epoch):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "    all_video_names = []\n",
        "    all_students = []\n",
        "    all_sessions = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        pbar = tqdm(val_loader, desc=f'Epoch {epoch+1} [Val]')\n",
        "        \n",
        "        for batch in pbar:\n",
        "            sequences = batch['sequence'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "            \n",
        "            outputs = model(sequences)\n",
        "            loss = criterion(outputs, labels)\n",
        "            \n",
        "            total_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "            \n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_video_names.extend(batch['video_name'])\n",
        "            all_students.extend(batch['student_id'])\n",
        "            all_sessions.extend(batch['session'])\n",
        "            \n",
        "            pbar.set_postfix({\n",
        "                'Loss': f'{loss.item():.4f}',\n",
        "                'Acc': f'{100.*correct/total:.2f}%'\n",
        "            })\n",
        "    \n",
        "    avg_loss = total_loss / len(val_loader)\n",
        "    accuracy = 100. * correct / total\n",
        "    \n",
        "    macro_f1 = f1_score(all_labels, all_predictions, average='macro')\n",
        "    \n",
        "    return avg_loss, accuracy, macro_f1, all_predictions, all_labels, all_video_names, all_students, all_sessions\n",
        "\n",
        "def train_model():\n",
        "    best_macro_f1 = 0\n",
        "    patience_counter = 0\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    train_accuracies = []\n",
        "    val_accuracies = []\n",
        "    macro_f1_scores = []\n",
        "    \n",
        "    print(f\"\\nStarting training for {TRAINING_CONFIG['num_epochs']} epochs...\")\n",
        "    \n",
        "    for epoch in range(TRAINING_CONFIG['num_epochs']):\n",
        "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, scheduler, epoch)\n",
        "        val_loss, val_acc, macro_f1, val_preds, val_labels, val_videos, val_students, val_sessions = validate_epoch(\n",
        "            model, val_loader, criterion, epoch\n",
        "        )\n",
        "        \n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        train_accuracies.append(train_acc)\n",
        "        val_accuracies.append(val_acc)\n",
        "        macro_f1_scores.append(macro_f1)\n",
        "        \n",
        "        print(f\"\\nEpoch {epoch+1}/{TRAINING_CONFIG['num_epochs']}:\")\n",
        "        print(f\"  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
        "        print(f\"  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
        "        print(f\"  Macro F1: {macro_f1:.4f}\")\n",
        "        \n",
        "        if macro_f1 > best_macro_f1:\n",
        "            best_macro_f1 = macro_f1\n",
        "            patience_counter = 0\n",
        "            \n",
        "            if TRAINING_CONFIG['save_best_model']:\n",
        "                torch.save({\n",
        "                    'epoch': epoch,\n",
        "                    'model_state_dict': model.state_dict(),\n",
        "                    'optimizer_state_dict': optimizer.state_dict(),\n",
        "                    'scheduler_state_dict': scheduler.state_dict(),\n",
        "                    'best_macro_f1': best_macro_f1,\n",
        "                    'config': TRAINING_CONFIG,\n",
        "                    'grs_mapping': GRS_MAPPING\n",
        "                }, 'best_timesformer_model.pth')\n",
        "                \n",
        "                print(f\"  âœ… New best model saved (Macro F1: {best_macro_f1:.4f})\")\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            print(f\"  Patience: {patience_counter}/{TRAINING_CONFIG['patience']}\")\n",
        "        \n",
        "        if patience_counter >= TRAINING_CONFIG['patience']:\n",
        "            print(f\"\\nEarly stopping triggered after {epoch+1} epochs\")\n",
        "            break\n",
        "    \n",
        "    return {\n",
        "        'train_losses': train_losses,\n",
        "        'val_losses': val_losses,\n",
        "        'train_accuracies': train_accuracies,\n",
        "        'val_accuracies': val_accuracies,\n",
        "        'macro_f1_scores': macro_f1_scores,\n",
        "        'best_macro_f1': best_macro_f1,\n",
        "        'final_predictions': val_preds,\n",
        "        'final_labels': val_labels,\n",
        "        'final_videos': val_videos,\n",
        "        'final_students': val_students,\n",
        "        'final_sessions': val_sessions\n",
        "    }\n",
        "\n",
        "training_history = train_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Evaluation and Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_training_history(history):\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "    \n",
        "    epochs = range(1, len(history['train_losses']) + 1)\n",
        "    \n",
        "    axes[0, 0].plot(epochs, history['train_losses'], 'b-', label='Train Loss')\n",
        "    axes[0, 0].plot(epochs, history['val_losses'], 'r-', label='Val Loss')\n",
        "    axes[0, 0].set_title('Training and Validation Loss')\n",
        "    axes[0, 0].set_xlabel('Epoch')\n",
        "    axes[0, 0].set_ylabel('Loss')\n",
        "    axes[0, 0].legend()\n",
        "    axes[0, 0].grid(True)\n",
        "    \n",
        "    axes[0, 1].plot(epochs, history['train_accuracies'], 'b-', label='Train Acc')\n",
        "    axes[0, 1].plot(epochs, history['val_accuracies'], 'r-', label='Val Acc')\n",
        "    axes[0, 1].set_title('Training and Validation Accuracy')\n",
        "    axes[0, 1].set_xlabel('Epoch')\n",
        "    axes[0, 1].set_ylabel('Accuracy (%)')\n",
        "    axes[0, 1].legend()\n",
        "    axes[0, 1].grid(True)\n",
        "    \n",
        "    axes[1, 0].plot(epochs, history['macro_f1_scores'], 'g-', label='Macro F1')\n",
        "    axes[1, 0].set_title('Macro F1 Score')\n",
        "    axes[1, 0].set_xlabel('Epoch')\n",
        "    axes[1, 0].set_ylabel('Macro F1')\n",
        "    axes[1, 0].legend()\n",
        "    axes[1, 0].grid(True)\n",
        "    \n",
        "    cm = confusion_matrix(history['final_labels'], history['final_predictions'])\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[1, 1],\n",
        "                xticklabels=GRS_MAPPING['labels'],\n",
        "                yticklabels=GRS_MAPPING['labels'])\n",
        "    axes[1, 1].set_title('Confusion Matrix')\n",
        "    axes[1, 1].set_xlabel('Predicted')\n",
        "    axes[1, 1].set_ylabel('Actual')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig('training_results.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "def analyze_session_performance(predictions, labels, sessions, students):\n",
        "    results_df = pd.DataFrame({\n",
        "        'prediction': predictions,\n",
        "        'label': labels,\n",
        "        'session': sessions,\n",
        "        'student': students\n",
        "    })\n",
        "    \n",
        "    print(f\"\\n=== SESSION-BASED ANALYSIS ===\")\n",
        "    \n",
        "    session_metrics = {}\n",
        "    for session in results_df['session'].unique():\n",
        "        session_data = results_df[results_df['session'] == session]\n",
        "        \n",
        "        accuracy = (session_data['prediction'] == session_data['label']).mean()\n",
        "        macro_f1 = f1_score(session_data['label'], session_data['prediction'], average='macro')\n",
        "        \n",
        "        session_metrics[session] = {\n",
        "            'accuracy': accuracy,\n",
        "            'macro_f1': macro_f1,\n",
        "            'count': len(session_data)\n",
        "        }\n",
        "        \n",
        "        print(f\"\\n{session} Session:\")\n",
        "        print(f\"  Sequences: {len(session_data)}\")\n",
        "        print(f\"  Accuracy: {accuracy:.3f}\")\n",
        "        print(f\"  Macro F1: {macro_f1:.3f}\")\n",
        "        \n",
        "        session_class_report = classification_report(\n",
        "            session_data['label'], session_data['prediction'],\n",
        "            target_names=GRS_MAPPING['labels'], output_dict=True\n",
        "        )\n",
        "        \n",
        "        print(f\"  Class-wise F1 scores:\")\n",
        "        for i, label in enumerate(GRS_MAPPING['labels']):\n",
        "            if str(i) in session_class_report:\n",
        "                f1 = session_class_report[str(i)]['f1-score']\n",
        "                print(f\"    {label}: {f1:.3f}\")\n",
        "    \n",
        "    return session_metrics\n",
        "\n",
        "def compute_expected_cost(predictions, labels):\n",
        "    num_classes = len(GRS_MAPPING['classes'])\n",
        "    cost_matrix = np.zeros((num_classes, num_classes))\n",
        "    \n",
        "    for i in range(num_classes):\n",
        "        for j in range(num_classes):\n",
        "            cost_matrix[i, j] = abs(i - j)\n",
        "    \n",
        "    total_cost = 0\n",
        "    for true_label, pred_label in zip(labels, predictions):\n",
        "        total_cost += cost_matrix[true_label, pred_label]\n",
        "    \n",
        "    return total_cost / len(labels)\n",
        "\n",
        "plot_training_history(training_history)\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"FINAL EVALUATION RESULTS\")\n",
        "print(f\"{'='*60}\")\n",
        "\n",
        "final_accuracy = (np.array(training_history['final_predictions']) == np.array(training_history['final_labels'])).mean()\n",
        "final_macro_f1 = f1_score(training_history['final_labels'], training_history['final_predictions'], average='macro')\n",
        "expected_cost = compute_expected_cost(training_history['final_predictions'], training_history['final_labels'])\n",
        "\n",
        "print(f\"\\nOverall Performance:\")\n",
        "print(f\"  Best Macro F1: {training_history['best_macro_f1']:.4f}\")\n",
        "print(f\"  Final Accuracy: {final_accuracy:.4f}\")\n",
        "print(f\"  Final Macro F1: {final_macro_f1:.4f}\")\n",
        "print(f\"  Expected Cost: {expected_cost:.4f}\")\n",
        "\n",
        "print(f\"\\nDetailed Classification Report:\")\n",
        "print(classification_report(\n",
        "    training_history['final_labels'],\n",
        "    training_history['final_predictions'],\n",
        "    target_names=GRS_MAPPING['labels']\n",
        "))\n",
        "\n",
        "session_metrics = analyze_session_performance(\n",
        "    training_history['final_predictions'],\n",
        "    training_history['final_labels'],\n",
        "    training_history['final_sessions'],\n",
        "    training_history['final_students']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Student-Level Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_student_performance():\n",
        "    print(f\"\\n=== STUDENT-LEVEL ANALYSIS ===\")\n",
        "    \n",
        "    results_df = pd.DataFrame({\n",
        "        'prediction': training_history['final_predictions'],\n",
        "        'label': training_history['final_labels'],\n",
        "        'session': training_history['final_sessions'],\n",
        "        'student': training_history['final_students'],\n",
        "        'video': training_history['final_videos']\n",
        "    })\n",
        "    \n",
        "    student_aggregated = results_df.groupby(['student', 'session']).agg({\n",
        "        'prediction': lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else x.iloc[0],\n",
        "        'label': lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else x.iloc[0],\n",
        "        'video': 'count'\n",
        "    }).rename(columns={'video': 'sequence_count'})\n",
        "    \n",
        "    student_aggregated['correct'] = (student_aggregated['prediction'] == student_aggregated['label'])\n",
        "    \n",
        "    print(f\"\\nStudent-level accuracy (aggregated by majority vote):\")\n",
        "    overall_student_accuracy = student_aggregated['correct'].mean()\n",
        "    print(f\"  Overall: {overall_student_accuracy:.3f}\")\n",
        "    \n",
        "    for session in student_aggregated.index.get_level_values('session').unique():\n",
        "        session_data = student_aggregated[student_aggregated.index.get_level_values('session') == session]\n",
        "        session_accuracy = session_data['correct'].mean()\n",
        "        print(f\"  {session}: {session_accuracy:.3f} ({len(session_data)} students)\")\n",
        "    \n",
        "    if len(student_aggregated.index.get_level_values('session').unique()) == 2:\n",
        "        print(f\"\\nPRE vs POST comparison:\")\n",
        "        \n",
        "        pre_data = student_aggregated[student_aggregated.index.get_level_values('session') == 'PRE']\n",
        "        post_data = student_aggregated[student_aggregated.index.get_level_values('session') == 'POST']\n",
        "        \n",
        "        pre_skills = pre_data['label'].value_counts().sort_index()\n",
        "        post_skills = post_data['label'].value_counts().sort_index()\n",
        "        \n",
        "        print(f\"\\nSkill distribution:\")\n",
        "        print(f\"  PRE:  {dict(pre_skills)}\")\n",
        "        print(f\"  POST: {dict(post_skills)}\")\n",
        "        \n",
        "        improvement_analysis = []\n",
        "        for student in pre_data.index.get_level_values('student'):\n",
        "            if student in post_data.index.get_level_values('student'):\n",
        "                pre_skill = pre_data.loc[student]['label']\n",
        "                post_skill = post_data.loc[student]['label']\n",
        "                improvement = post_skill - pre_skill\n",
        "                improvement_analysis.append(improvement)\n",
        "        \n",
        "        if improvement_analysis:\n",
        "            avg_improvement = np.mean(improvement_analysis)\n",
        "            improved_students = sum(1 for x in improvement_analysis if x > 0)\n",
        "            total_paired = len(improvement_analysis)\n",
        "            \n",
        "            print(f\"\\nSkill improvement analysis:\")\n",
        "            print(f\"  Students with both PRE/POST: {total_paired}\")\n",
        "            print(f\"  Students who improved: {improved_students} ({improved_students/total_paired*100:.1f}%)\")\n",
        "            print(f\"  Average skill change: {avg_improvement:.2f} levels\")\n",
        "    \n",
        "    return student_aggregated\n",
        "\n",
        "def create_submission_file():\n",
        "    print(f\"\\n=== CREATING SUBMISSION FILE ===\")\n",
        "    \n",
        "    results_df = pd.DataFrame({\n",
        "        'video_name': training_history['final_videos'],\n",
        "        'prediction': training_history['final_predictions'],\n",
        "        'label': training_history['final_labels'],\n",
        "        'session': training_history['final_sessions'],\n",
        "        'student': training_history['final_students']\n",
        "    })\n",
        "    \n",
        "    video_predictions = results_df.groupby('video_name').agg({\n",
        "        'prediction': lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else x.iloc[0],\n",
        "        'label': lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else x.iloc[0],\n",
        "        'session': 'first',\n",
        "        'student': 'first'\n",
        "    })\n",
        "    \n",
        "    submission_df = pd.DataFrame({\n",
        "        'video_name': video_predictions.index,\n",
        "        'predicted_grs_class': video_predictions['prediction'],\n",
        "        'predicted_grs_label': [GRS_MAPPING['labels'][pred] for pred in video_predictions['prediction']]\n",
        "    })\n",
        "    \n",
        "    submission_df.to_csv('task1_submission.csv', index=False)\n",
        "    \n",
        "    print(f\"Submission file created: task1_submission.csv\")\n",
        "    print(f\"  Videos: {len(submission_df)}\")\n",
        "    print(f\"  Predictions distribution:\")\n",
        "    pred_dist = submission_df['predicted_grs_label'].value_counts()\n",
        "    for label, count in pred_dist.items():\n",
        "        print(f\"    {label}: {count}\")\n",
        "    \n",
        "    return submission_df\n",
        "\n",
        "student_analysis = analyze_student_performance()\n",
        "submission_df = create_submission_file()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Save Results and Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "final_results = {\n",
        "    'model_config': {\n",
        "        'architecture': 'TimeSformer',\n",
        "        'model_size': 'base',\n",
        "        'num_classes': len(GRS_MAPPING['classes']),\n",
        "        'sequence_length': CONFIG['sequence_length'],\n",
        "        'input_size': CONFIG['frame_size']\n",
        "    },\n",
        "    'training_config': TRAINING_CONFIG,\n",
        "    'dataset_info': metadata['dataset_info'],\n",
        "    'performance_metrics': {\n",
        "        'best_macro_f1': training_history['best_macro_f1'],\n",
        "        'final_accuracy': final_accuracy,\n",
        "        'final_macro_f1': final_macro_f1,\n",
        "        'expected_cost': expected_cost\n",
        "    },\n",
        "    'training_history': training_history,\n",
        "    'session_metrics': session_metrics,\n",
        "    'grs_mapping': GRS_MAPPING\n",
        "}\n",
        "\n",
        "with open('task1_results.json', 'w') as f:\n",
        "    json.dump(final_results, f, indent=2, default=str)\n",
        "\n",
        "torch.save({\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'config': CONFIG,\n",
        "    'training_config': TRAINING_CONFIG,\n",
        "    'grs_mapping': GRS_MAPPING,\n",
        "    'performance': final_results['performance_metrics']\n",
        "}, 'final_timesformer_model.pth')\n",
        "\n",
        "print(f\"\\nâœ… Training completed successfully!\")\n",
        "print(f\"\\nFiles saved:\")\n",
        "print(f\"  - best_timesformer_model.pth (best model checkpoint)\")\n",
        "print(f\"  - final_timesformer_model.pth (final model)\")\n",
        "print(f\"  - task1_results.json (complete results)\")\n",
        "print(f\"  - task1_submission.csv (submission file)\")\n",
        "print(f\"  - training_results.png (training plots)\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"AIXSUTURE TIMESFORMER TRAINING SUMMARY\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"ðŸŽ¯ Task: Global Rating Score Classification\")\n",
        "print(f\"ðŸ—ï¸ Model: TimeSformer (base, {total_params:,} parameters)\")\n",
        "print(f\"ðŸ“Š Dataset: {metadata['dataset_info']['total_videos']} videos, {metadata['dataset_info']['total_students']} students\")\n",
        "print(f\"ðŸ”„ Sessions: {metadata['dataset_info']['sessions']}\")\n",
        "print(f\"ðŸ‘¥ Investigators: {len(metadata['dataset_info']['investigators'])} raters\")\n",
        "print(f\"ðŸŽ¥ Sequences: {len(train_data)} train, {len(val_data)} val\")\n",
        "print(f\"ðŸ“ˆ Best Macro F1: {training_history['best_macro_f1']:.4f}\")\n",
        "print(f\"ðŸŽ¯ Final Accuracy: {final_accuracy:.4f}\")\n",
        "print(f\"ðŸ’° Expected Cost: {expected_cost:.4f}\")\n",
        "print(f\"âš¡ Training: {len(training_history['train_losses'])} epochs\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "print(f\"\\nNext steps:\")\n",
        "print(f\"1. Analyze results by session (PRE vs POST training)\")\n",
        "print(f\"2. Compare with inter-rater reliability metrics\")\n",
        "print(f\"3. Submit task1_submission.csv to OSS Challenge\")\n",
        "print(f\"4. Consider ensemble methods for improved performance\")\n",
        "print(f\"5. Extend to Task 2 (OSATS criteria prediction)\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "SI",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
